{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import astropy.io.ascii as ascii\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import match_coordinates_sky\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.image as mp\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import matplotlib.image as mp\n",
    "from astropy.visualization import LinearStretch\n",
    "from astropy.visualization import ZScaleInterval\n",
    "from astropy.visualization import ImageNormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions needed for the matching process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match1(poi, catalogue):\n",
    "    \n",
    "    x=poi['X_WORLD']\n",
    "    y=poi['Y_WORLD']\n",
    "\n",
    "    coord1 = SkyCoord(ra=[x]*u.degree, dec=[y]*u.degree)\n",
    "    coord2 = SkyCoord(ra=catalogue['X_WORLD']*u.degree, dec=catalogue['Y_WORLD']*u.degree)\n",
    "\n",
    "    idx, d2d, d3d = coord1.match_to_catalog_sky(coord2)\n",
    "    max_sep = 1.0 * u.arcsec\n",
    "    sep_constraint = d2d < max_sep\n",
    "    global catalogue_match\n",
    "    catalogue_match = catalogue.iloc[idx[sep_constraint]]\n",
    "    \n",
    "    \n",
    "def match2(catalogue1, catalogue2):\n",
    "    xworld1 = catalogue1['X_WORLD']\n",
    "    yworld1 = catalogue1['Y_WORLD']\n",
    "\n",
    "    xworld2 = catalogue2['X_WORLD']\n",
    "    yworld2 = catalogue2['Y_WORLD']\n",
    "\n",
    "    coord1 = SkyCoord(ra=xworld1*u.degree, dec=yworld1*u.degree)\n",
    "    coord2 = SkyCoord(ra=xworld2*u.degree, dec=yworld2*u.degree)\n",
    "\n",
    "    idx, d2d, d3d = coord1.match_to_catalog_sky(coord2)\n",
    "\n",
    "    max_sep = 1.0 * u.arcsec\n",
    "\n",
    "    sep_constraint = d2d < max_sep\n",
    "\n",
    "    global data1_12_matches\n",
    "    try: data1_12_matches = catalogue1[sep_constraint]\n",
    "    except IndexError: \n",
    "        pass \n",
    "    \n",
    "    global data2_12_matches\n",
    "    data2_12_matches = catalogue2.iloc[idx[sep_constraint]]\n",
    "\n",
    "    \n",
    "def match3(catalogue1, catalogue2, catalogue3):\n",
    "    xworld1 = catalogue1['X_WORLD']\n",
    "    yworld1 = catalogue1['Y_WORLD']\n",
    "\n",
    "    xworld2 = catalogue2['X_WORLD']\n",
    "    yworld2 = catalogue2['Y_WORLD']\n",
    "    \n",
    "    xworld3 = catalogue3['X_WORLD']\n",
    "    yworld3 = catalogue3['Y_WORLD']\n",
    "    \n",
    "    coord1 = SkyCoord(ra=xworld1*u.degree, dec=yworld1*u.degree)\n",
    "    coord2 = SkyCoord(ra=xworld2*u.degree, dec=yworld2*u.degree)\n",
    "\n",
    "    \n",
    "    idx, d2d, d3d = coord1.match_to_catalog_sky(coord2)\n",
    "    \n",
    "    max_sep = 1.0 * u.arcsec\n",
    "\n",
    "    sep_constraint = d2d < max_sep\n",
    "    \n",
    "    data1_12_matches = catalogue1[sep_constraint]\n",
    "    data2_12_matches = catalogue2.iloc[idx[sep_constraint]]\n",
    "    \n",
    "    xworld1_12 = data1_12_matches['X_WORLD']\n",
    "    yworld1_12 = data1_12_matches['Y_WORLD']\n",
    "    \n",
    "    coord1_12 = SkyCoord(ra=xworld1_12*u.degree, dec=yworld1_12*u.degree)\n",
    "    coord3 = SkyCoord(ra=xworld3*u.degree, dec=yworld3*u.degree)\n",
    "    \n",
    "    idx, d2d, d3d = coord1_12.match_to_catalog_sky(coord3)\n",
    "    \n",
    "    max_sep = 1.0 * u.arcsec\n",
    "\n",
    "    sep_constraint = d2d < max_sep\n",
    "    \n",
    "    global data1_123_matches\n",
    "    data1_123_matches = data1_12_matches[sep_constraint]\n",
    "    global data2_123_matches\n",
    "    data2_123_matches = data2_12_matches[sep_constraint]\n",
    "    global data3_123_matches\n",
    "    data3_123_matches = catalogue3.iloc[idx[sep_constraint]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for the inputs when typing in the terminal. Make sure that these are the subtraction images and g data should be first for the light curve labels to be correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nargs = len(sys.argv) - 1\n",
    "if nargs == 12: \n",
    "    df1 = pd.read_csv(sys.argv[1])\n",
    "    df2 = pd.read_csv(sys.argv[2])\n",
    "    df3 = pd.read_csv(sys.argv[3])\n",
    "    df4 = pd.read_csv(sys.argv[4])\n",
    "    df5 = pd.read_csv(sys.argv[5])\n",
    "    df6 = pd.read_csv(sys.argv[6])\n",
    "    r7 = ascii.read(sys.argv[7])\n",
    "    r8 = ascii.read(sys.argv[8])\n",
    "    r9 = ascii.read(sys.argv[9])\n",
    "    r10 = ascii.read(sys.argv[10])\n",
    "    r11 = ascii.read(sys.argv[11])\n",
    "    r12 = ascii.read(sys.argv[12])\n",
    "\n",
    "else:\n",
    "    print(\"Error: Arguments invalid\")\n",
    "    print('Example: python Make_Lightcurves.py g1_SUB.cat g2_SUB.cat g3_SUB.cat i1_SUB.cat i2_SUB.cat i3_SUB.cat' +\n",
    "          'g1_SCI.cat g2_SCI.cat g3_SCI.cat i1_SCI.cat i2_SCI.cat i3_SCI.cat')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in the cat files as panda dataframes\n",
    "df7 = pd.DataFrame(r7.as_array())\n",
    "df8 = pd.DataFrame(r8.as_array())\n",
    "df9 = pd.DataFrame(r9.as_array())\n",
    "df10 = pd.DataFrame(r10.as_array())\n",
    "df11 = pd.DataFrame(r11.as_array())\n",
    "df12 = pd.DataFrame(r12.as_array())\n",
    "\n",
    "print('data points in first file:', len(df1))\n",
    "print('data points in second file:', len(df2))\n",
    "print('data points in third file:', len(df3))\n",
    "print('data points in fourth file:', len(df4))\n",
    "print('data points in fifth file:', len(df5))\n",
    "print('data points in sixth file:', len(df6))\n",
    "\n",
    "print('data points in seventh file:', len(r7))\n",
    "print('data points in eighth file:', len(r8))\n",
    "print('data points in ninth file:', len(r9))\n",
    "print('data points in tenth file:', len(r10))\n",
    "print('data points in eleventh file:', len(r11))\n",
    "print('data points in twelfth file:', len(r12))\n",
    "\n",
    "#getting rid of the points in the sub images with a mag_auto of greater than 20 as these are errors\n",
    "# df1f = df1[df1['MAG_AUTO'] < 20]\n",
    "# df2f = df2[df2['MAG_AUTO'] < 20]\n",
    "# df3f = df3[df3['MAG_AUTO'] < 20] \n",
    "# df4f = df4[df4['MAG_AUTO'] < 20]\n",
    "# df5f = df5[df5['MAG_AUTO'] < 20]\n",
    "# df6f = df6[df6['MAG_AUTO'] < 20]\n",
    "df1f = df1.drop(columns = 'Unnamed: 0')\n",
    "df2f = df2.drop(columns = 'Unnamed: 0')\n",
    "df3f = df3.drop(columns = 'Unnamed: 0')\n",
    "df4f = df4.drop(columns = 'Unnamed: 0')\n",
    "df5f = df5.drop(columns = 'Unnamed: 0')\n",
    "df6f = df6.drop(columns = 'Unnamed: 0')\n",
    "df7f = df7[df7['MAG_AUTO'] < 25]\n",
    "df8f = df8[df8['MAG_AUTO'] < 25]\n",
    "df9f = df9[df9['MAG_AUTO'] < 25]\n",
    "df10f = df10[df10['MAG_AUTO'] < 25]\n",
    "df11f = df11[df11['MAG_AUTO'] < 25]\n",
    "df12f = df12[df12['MAG_AUTO'] < 25]\n",
    "\n",
    "\n",
    "print('valid data points in first file:', len(df1f))\n",
    "print('valid data points in second file:', len(df2f))\n",
    "print('valid data points in third file:', len(df3f))\n",
    "print('valid data points in fourth file:', len(df4f))\n",
    "print('valid data points in fifth file:', len(df5f))\n",
    "print('valid data points in sixth file:', len(df6f))\n",
    "\n",
    "print('valid data points in seventh file:', len(df7f))\n",
    "print('valid data points in eighth file:', len(df8f))\n",
    "print('valid data points in ninth file:', len(df9f))\n",
    "print('valid data points in tenth file:', len(df10f))\n",
    "print('valid data points in eleventh file:', len(df11f))\n",
    "print('valid data points in twelfth file:', len(df12f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code below is for the matching process and making the lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match3(df1f, df2f, df3f) #finding common sources over the 3 inputs\n",
    "print('There are', len(data1_123_matches), 'matches between the first 3 files')\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# Making the panda dataframes needed for exporting all of the data\n",
    "mag_csv = [] #dataframe for exporting to csv \n",
    "gsub1 = []\n",
    "gsub2 = []\n",
    "gsub3 = []\n",
    "isub1 = []\n",
    "isub2 = []\n",
    "isub3 = []\n",
    "gsci1 = []\n",
    "gsci2 = []\n",
    "gsci3 = []\n",
    "isci1 = []\n",
    "isci2 = []\n",
    "isci3 = []\n",
    "\n",
    "xgsub1 = []\n",
    "xgsub2 = []\n",
    "xgsub3 = [] \n",
    "xisub1 = [] \n",
    "xisub2 = []\n",
    "xisub3 = []\n",
    "xgsci1 = []\n",
    "xgsci2 = []\n",
    "xgsci3 = [] \n",
    "xisci1 = [] \n",
    "xisci2 = []\n",
    "xisci3 = []\n",
    "\n",
    "ygsub1 = []\n",
    "ygsub2 = []\n",
    "ygsub3 = [] \n",
    "yisub1 = [] \n",
    "yisub2 = []\n",
    "yisub3 = []\n",
    "ygsci1 = []\n",
    "ygsci2 = []\n",
    "ygsci3 = [] \n",
    "yisci1 = [] \n",
    "yisci2 = []\n",
    "yisci3 = []\n",
    "\n",
    "FWHMgsub1 = []\n",
    "FWHMgsub2 = []\n",
    "FWHMgsub3 = []\n",
    "FWHMisub1 = []\n",
    "FWHMisub2 = []\n",
    "FWHMisub3 = []\n",
    "FWHMgsci1 = []\n",
    "FWHMgsci2 = []\n",
    "FWHMgsci3 = []\n",
    "FWHMisci1 = []\n",
    "FWHMisci2 = []\n",
    "FWHMisci3 = []\n",
    "\n",
    "mag_csv = pd.DataFrame(mag_csv)\n",
    "gsub1 = pd.DataFrame(gsub1)\n",
    "gsub2 = pd.DataFrame(gsub2)\n",
    "gsub3 = pd.DataFrame(gsub3)\n",
    "isub1 = pd.DataFrame(isub1)\n",
    "isub2 = pd.DataFrame(isub2)\n",
    "isub3 = pd.DataFrame(isub3)\n",
    "gsci1 = pd.DataFrame(gsci1)\n",
    "gsci2 = pd.DataFrame(gsci2)\n",
    "gsci3 = pd.DataFrame(gsci3)\n",
    "isci1 = pd.DataFrame(isci1)\n",
    "isci2 = pd.DataFrame(isci2)\n",
    "isci3 = pd.DataFrame(isci3)\n",
    "\n",
    "xgsub1 = pd.DataFrame(xgsub1)\n",
    "xgsub2 = pd.DataFrame(xgsub2)\n",
    "xgsub3 = pd.DataFrame(xgsub3)\n",
    "xisub1 = pd.DataFrame(xisub1)\n",
    "xisub2 = pd.DataFrame(xisub2)\n",
    "xisub3 = pd.DataFrame(xisub3)\n",
    "xgsci1 = pd.DataFrame(xgsci1)\n",
    "xgsci2 = pd.DataFrame(xgsci2)\n",
    "xgsci3 = pd.DataFrame(xgsci3)\n",
    "xisci1 = pd.DataFrame(xisci1)\n",
    "xisci2 = pd.DataFrame(xisci2)\n",
    "xisci3 = pd.DataFrame(xisci3)\n",
    "\n",
    "ygsub1 = pd.DataFrame(ygsub1)\n",
    "ygsub2 = pd.DataFrame(ygsub2)\n",
    "ygsub3 = pd.DataFrame(ygsub3)\n",
    "yisub1 = pd.DataFrame(yisub1)\n",
    "yisub2 = pd.DataFrame(yisub2)\n",
    "yisub3 = pd.DataFrame(yisub3)\n",
    "ygsci1 = pd.DataFrame(ygsci1)\n",
    "ygsci2 = pd.DataFrame(ygsci2)\n",
    "ygsci3 = pd.DataFrame(ygsci3)\n",
    "yisci1 = pd.DataFrame(yisci1)\n",
    "yisci2 = pd.DataFrame(yisci2)\n",
    "yisci3 = pd.DataFrame(yisci3)\n",
    "\n",
    "FWHMgsub1 = pd.DataFrame(FWHMgsub1)\n",
    "FWHMgsub2 = pd.DataFrame(FWHMgsub2)\n",
    "FWHMgsub3 = pd.DataFrame(FWHMgsub3)\n",
    "FWHMisub1 = pd.DataFrame(FWHMisub1)\n",
    "FWHMisub2 = pd.DataFrame(FWHMisub2)\n",
    "FWHMisub3 = pd.DataFrame(FWHMisub3)\n",
    "FWHMgsci1 = pd.DataFrame(FWHMgsci1)\n",
    "FWHMgsci2 = pd.DataFrame(FWHMgsci2)\n",
    "FWHMgsci3 = pd.DataFrame(FWHMgsci3)\n",
    "FWHMisci1 = pd.DataFrame(FWHMisci1)\n",
    "FWHMisci2 = pd.DataFrame(FWHMisci2)\n",
    "FWHMisci3 = pd.DataFrame(FWHMisci3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data1_123_matches)): #looping over all matches\n",
    "    \n",
    "    script_dir = os.path.dirname(__file__) #this is is preparation to make a file in the terminal \n",
    "    results_dir = os.path.join(script_dir, 'Lightcurves/')\n",
    "    if not os.path.isdir(results_dir): #makes a directory if there isnt one called 'Lightcurves'\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    \n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "    #data points for the subtraction g band \n",
    "    \n",
    "    \n",
    "    \n",
    "    time_g_sub = [8,9,10] # for the x axis of the first light curve \n",
    "    lc_g_sub = [] #dataframe for the points in the subtraction light curve\n",
    "    lc_g_sub = pd.DataFrame(lc_g_sub)\n",
    "    \n",
    "    lc_g_sub = lc_g_sub.append(data1_123_matches.iloc[i]) #adding in the first data point\n",
    "    gsub1 = gsub1.append(data1_123_matches.iloc[i,12:13]) #adding in the mag auto for the csv file\n",
    "    xgsub1 = xgsub1.append(data1_123_matches.iloc[i,8:9]) #adding in the xworld for the csv file\n",
    "    ygsub1 = ygsub1.append(data1_123_matches.iloc[i,9:10]) # adding in the yworld for the csv file \n",
    "    FWHMgsub1 = FWHMgsub1.append(data1_123_matches.iloc[i,23:24]) #adding in the FWHM for the csv file\n",
    "    \n",
    "    lc_g_sub = lc_g_sub.append(data2_123_matches.iloc[i]) # second data point\n",
    "    gsub2 = gsub2.append(data2_123_matches.iloc[i,12:13])\n",
    "    xgsub2 = xgsub2.append(data2_123_matches.iloc[i,8:9])\n",
    "    ygsub2 = ygsub2.append(data2_123_matches.iloc[i,9:10])\n",
    "    FWHMgsub2 = FWHMgsub2.append(data2_123_matches.iloc[i,23:24])\n",
    "    \n",
    "    lc_g_sub = lc_g_sub.append(data3_123_matches.iloc[i]) # third data point \n",
    "    gsub3 = gsub3.append(data3_123_matches.iloc[i,12:13])\n",
    "    xgsub3 = xgsub3.append(data3_123_matches.iloc[i,8:9])\n",
    "    ygsub3 = ygsub3.append(data3_123_matches.iloc[i,9:10])\n",
    "    FWHMgsub3 = FWHMgsub3.append(data3_123_matches.iloc[i,23:24])\n",
    "    \n",
    "    \n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "    # data points for the science g band\n",
    "    \n",
    "    \n",
    "    time_g_sci = []\n",
    "    lc_g_sci = [] #dataframe for the points in the science light curve\n",
    "    lc_g_sci = pd.DataFrame(lc_g_sci)\n",
    "    \n",
    "    #matching for the science catalogue and adding data point to science light curve\n",
    "    \n",
    "    match1(data1_123_matches.iloc[i,8:10], df7f)\n",
    "    if catalogue_match.empty == False: #if the catalogue match is not a nan, then add it to the second lightcurve\n",
    "        lc_g_sci = lc_g_sci.append(catalogue_match)\n",
    "        time_g_sci.append(8)\n",
    "        gsci1 = gsci1.append(catalogue_match.iloc[:,12:13])\n",
    "        xgsci1 = xgsci1.append(catalogue_match.iloc[:,8:9])\n",
    "        ygsci1 = ygsci1.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMgsci1 = FWHMgsci1.append(catalogue_match.iloc[:,23:24])\n",
    "    else:\n",
    "        gsci1 = gsci1.append([np.nan])\n",
    "        xgsci1 = xgsci1.append([np.nan])\n",
    "        ygsci1 = ygsci1.append([np.nan])\n",
    "        FWHMgsci1 = FWHMgsci1.append([np.nan])\n",
    "        pass\n",
    "    \n",
    "    match1(data1_123_matches.iloc[i,8:10], df8f)\n",
    "    if catalogue_match.empty == False: #if the catalogue match is not a nan, then add it to the second lightcurve\n",
    "        lc_g_sci = lc_g_sci.append(catalogue_match)\n",
    "        time_g_sci.append(9)\n",
    "        gsci2 = gsci2.append(catalogue_match.iloc[:,12:13])\n",
    "        xgsci2 = xgsci2.append(catalogue_match.iloc[:,8:9])\n",
    "        ygsci2 = ygsci2.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMgsci2 = FWHMgsci2.append(catalogue_match.iloc[:,23:24])\n",
    "    else:\n",
    "        gsci2 = gsci2.append([np.nan])\n",
    "        xgsci2 = xgsci2.append([np.nan])\n",
    "        ygsci2 = ygsci2.append([np.nan])\n",
    "        FWHMgsci2 = FWHMgsci2.append([np.nan])\n",
    "        pass\n",
    "    \n",
    "    match1(data1_123_matches.iloc[i,8:10], df9f)\n",
    "    if catalogue_match.empty == False: #if the catalogue match is not a nan, then add it to the second lightcurve\n",
    "        lc_g_sci = lc_g_sci.append(catalogue_match)\n",
    "        time_g_sci.append(10)\n",
    "        gsci3 = gsci3.append(catalogue_match.iloc[:,12:13])\n",
    "        xgsci3 = xgsci3.append(catalogue_match.iloc[:,8:9])\n",
    "        ygsci3 = ygsci3.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMgsci3 = FWHMgsci3.append(catalogue_match.iloc[:,23:24])\n",
    "    else:\n",
    "        gsci3 = gsci3.append([np.nan])\n",
    "        xgsci3 = xgsci3.append([np.nan])\n",
    "        ygsci3 = ygsci3.append([np.nan])\n",
    "        FWHMgsci3 = FWHMgsci3.append([np.nan])\n",
    "        pass\n",
    "    \n",
    "    \n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "    # data points for the subtraction i band\n",
    "    \n",
    "    \n",
    "    #making some dataframes for the subtraction i band \n",
    "    time_i_sub = []\n",
    "    lc_i_sub = []\n",
    "    lc_i_sub = pd.DataFrame(lc_i_sub)\n",
    "    \n",
    "    #matching for the subtraction catalogue in the i band for the subtraction light curve \n",
    "    match1(data1_123_matches.iloc[i,8:10], df4f) #finding the source in the i subtraction image (08) & appending into lightcurve\n",
    "    if catalogue_match.empty == False: #if the catalogue match is not a nan, then add it to the second lightcurve\n",
    "        lc_i_sub = lc_i_sub.append(catalogue_match)\n",
    "        time_i_sub.append(8)\n",
    "        isub1 = isub1.append(catalogue_match.iloc[:,12:13])\n",
    "        xisub1 = xisub1.append(catalogue_match.iloc[:,8:9])\n",
    "        yisub1 = yisub1.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMisub1 = FWHMisub1.append(catalogue_match.iloc[:,23:24])\n",
    "    else:\n",
    "        isub1 = isub1.append([np.nan])\n",
    "        xisub1 = xisub1.append([np.nan])\n",
    "        yisub1 = yisub1.append([np.nan])\n",
    "        FWHMisub1 = FWHMisub1.append([np.nan])\n",
    "        pass \n",
    "\n",
    "    match1(data1_123_matches.iloc[i,8:10], df5f) #finding the source in the subtraction i image (09) etc \n",
    "    if catalogue_match.empty == False:\n",
    "        lc_i_sub = lc_i_sub.append(catalogue_match)\n",
    "        time_i_sub.append(9)\n",
    "        isub2 = isub2.append(catalogue_match.iloc[:,12:13])\n",
    "        xisub2 = xisub2.append(catalogue_match.iloc[:,8:9])\n",
    "        yisub2 = yisub2.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMisub2 = FWHMisub2.append(catalogue_match.iloc[:,23:24])\n",
    "    else:\n",
    "        isub2 = isub2.append([np.nan])\n",
    "        xisub2 = xisub2.append([np.nan])\n",
    "        yisub2 = yisub2.append([np.nan])\n",
    "        FWHMisub2 = FWHMisub2.append([np.nan])\n",
    "        pass \n",
    "        \n",
    "    match1(data1_123_matches.iloc[i,8:10], df6f)\n",
    "    if catalogue_match.empty == False:\n",
    "        lc_i_sub = lc_i_sub.append(catalogue_match)\n",
    "        time_i_sub.append(10)\n",
    "        isub3 = isub3.append(catalogue_match.iloc[:,12:13])\n",
    "        xisub3 = xisub3.append(catalogue_match.iloc[:,8:9])\n",
    "        yisub3 = yisub3.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMisub3 = FWHMisub3.append(catalogue_match.iloc[:,23:24])\n",
    "    else: \n",
    "        isub3 = isub3.append([np.nan])\n",
    "        xisub3 = xisub3.append([np.nan])\n",
    "        yisub3 = yisub3.append([np.nan])\n",
    "        FWHMisub3 = FWHMisub3.append([np.nan])\n",
    "        pass\n",
    "\n",
    "    \n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "    # data points for the science i band \n",
    "    \n",
    "    time_i_sci = []\n",
    "    lc_i_sci = []\n",
    "    lc_i_sci = pd.DataFrame(lc_i_sci)\n",
    "    \n",
    "    match1(data1_123_matches.iloc[i,8:10], df10f)\n",
    "    if catalogue_match.empty == False: #if the catalogue match is not a nan, then add it to the second lightcurve\n",
    "        lc_i_sci = lc_i_sci.append(catalogue_match)\n",
    "        time_i_sci.append(8)\n",
    "        isci1 = isci1.append(catalogue_match.iloc[:,12:13])\n",
    "        xisci1 = xisci1.append(catalogue_match.iloc[:,8:9])\n",
    "        yisci1 = yisci1.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMisci1 = FWHMisci1.append(catalogue_match.iloc[:,23:24])\n",
    "    else:\n",
    "        isci1 = isci1.append([np.nan])\n",
    "        xisci1 = xisci1.append([np.nan])\n",
    "        yisci1 = yisci1.append([np.nan])\n",
    "        FWHMisci1 = FWHMisci1.append([np.nan])\n",
    "        pass\n",
    "    \n",
    "    match1(data1_123_matches.iloc[i,8:10], df11f)\n",
    "    if catalogue_match.empty == False: #if the catalogue match is not a nan, then add it to the second lightcurve\n",
    "        lc_i_sci = lc_i_sci.append(catalogue_match)\n",
    "        time_i_sci.append(9)\n",
    "        isci2 = isci2.append(catalogue_match.iloc[:,12:13])\n",
    "        xisci2 = xisci2.append(catalogue_match.iloc[:,8:9])\n",
    "        yisci2 = yisci2.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMisci2 = FWHMisci2.append(catalogue_match.iloc[:,23:24])\n",
    "    else:\n",
    "        isci2 = isci2.append([np.nan])\n",
    "        xisci2 = xisci2.append([np.nan])\n",
    "        yisci2 = yisci2.append([np.nan])\n",
    "        FWHMisci2 = FWHMisci2.append([np.nan])\n",
    "        pass\n",
    "    \n",
    "    match1(data1_123_matches.iloc[i,8:10], df12f)\n",
    "    if catalogue_match.empty == False: #if the catalogue match is not a nan, then add it to the second lightcurve\n",
    "        lc_i_sci = lc_i_sci.append(catalogue_match)\n",
    "        time_i_sci.append(10)\n",
    "        isci3 = isci3.append(catalogue_match.iloc[:,12:13])\n",
    "        xisci3 = xisci3.append(catalogue_match.iloc[:,8:9])\n",
    "        yisci3 = yisci3.append(catalogue_match.iloc[:,9:10])\n",
    "        FWHMisci3 = FWHMisci3.append(catalogue_match.iloc[:,23:24])\n",
    "    else:\n",
    "        isci3 = isci3.append([np.nan])\n",
    "        xisci3 = xisci3.append([np.nan])\n",
    "        yisci3 = yisci3.append([np.nan])\n",
    "        FWHMisci3 = FWHMisci3.append([np.nan])\n",
    "        pass\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "    # making the points for the 'colour' in the subtraction image\n",
    "\n",
    "    if bool(time_i_sub) == True & bool(time_g_sub) == True: #if time_i_sub is not empty, execute the next steps, otherwise pass\n",
    "        mag_g_sub = lc_g_sub['MAG_AUTO']\n",
    "        mag_i_sub = lc_i_sub['MAG_AUTO']\n",
    "        \n",
    "        mag_g_subm = mag_g_sub.reset_index()\n",
    "        mag_i_subm = mag_i_sub.reset_index()\n",
    "        \n",
    "        mag_g_subm = mag_g_subm['MAG_AUTO']\n",
    "        mag_i_subm = mag_i_subm['MAG_AUTO']\n",
    "        \n",
    "        mag_diff_sub = mag_g_subm - mag_i_subm\n",
    "    else: \n",
    "        pass\n",
    "    \n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "    \n",
    "    # making the points for the 'colour' in the science image\n",
    "\n",
    "    if bool(time_i_sci) == True & bool(time_g_sci) == True: #if time_i_sub is not empty, execute the next steps, otherwise pass\n",
    "        mag_g_sci = lc_g_sci['MAG_AUTO']\n",
    "        mag_i_sci = lc_i_sci['MAG_AUTO']\n",
    "        \n",
    "        mag_g_scim = mag_g_sci.reset_index()\n",
    "        mag_i_scim = mag_i_sci.reset_index()\n",
    "        \n",
    "        mag_g_scim = mag_g_scim['MAG_AUTO']\n",
    "        mag_i_scim = mag_i_scim['MAG_AUTO']\n",
    "        \n",
    "        mag_diff_sci = mag_g_scim - mag_i_scim\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "    # plotting the subtraction light curve  \n",
    "    \n",
    "    RA_sub = lc_g_sub['X_WORLD'] #these will be for the title of the light curves \n",
    "    Dec_sub = lc_g_sub['Y_WORLD']\n",
    "    \n",
    "    fig, ax = plt.subplots(2, figsize = (10,14), sharey = False) #light curve plotting parameters \n",
    "    ax0 = plt.subplot(2,1,1)\n",
    "    plt.title('RA: '+ str(RA_sub.iloc[0]) + ' Dec: '+  str(Dec_sub.iloc[0])) #RA and Dec of the first data point in te dataframe in this case it is the RA and Dec of the subtraction point in 08\n",
    "    ax0.set_xlabel('Date')\n",
    "    ax0.set_ylabel('Magnitude in subtraction image', color = 'black')\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax0.plot(time_g_sub, mag_g_sub, color ='g', marker = 'o', label = 'g')\n",
    "    \n",
    "    \n",
    "    if bool(time_i_sub) == True: #if there are any points for the i band, plot them down, otherwise do nothing\n",
    "        ax0.plot(time_i_sub, mag_i_sub, color = 'grey', marker = 'o', label = 'i')\n",
    "        plt.legend()\n",
    "\n",
    "        ax1 = ax0.twinx()  # initiates a second axes that shares the same x-axis for the 'colour' plot \n",
    "        ax1.set_ylabel('g - i', color = 'r')  # we already handled the x-label with ax1\n",
    "        ax1.tick_params(axis='y', labelcolor = 'r')\n",
    "        ax1.plot(time_g_sub, mag_diff_sub, color = 'r', marker = 'x', label = 'g-i')\n",
    "        \n",
    "    else:\n",
    "        plt.legend()\n",
    "        pass\n",
    "\n",
    "#     plt.locator_params(axis = 'y', nbins = 10) #limiting the x-axis and y-axis\n",
    "#     plt.locator_params(axis='x', nbins=10)\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "    \n",
    "    # plotting the science light curve\n",
    "   \n",
    "#     RA_sci = lc_g_sci['X_WORLD'] #these will be for the title of the light curves \n",
    "#     Dec_sci = lc_g_sci['Y_WORLD']\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    \n",
    "    if bool(time_g_sci) == True:# if there are any points in the science g band, plot them down \n",
    "#         plt.title('RA: '+ str(RA_sci.iloc[0]) + ' Dec: '+  str(Dec_sci.iloc[0]))\n",
    "        ax2.set_xlabel('Date')\n",
    "        ax2.set_ylabel('Magnitude in science image', color = 'black')\n",
    "        try:\n",
    "            ax2.plot(time_g_sci, mag_g_sci, color ='g', marker = 'o', label = 'g')\n",
    "            \n",
    "        except(ValueError): \n",
    "            pass\n",
    "            \n",
    "        \n",
    "    else: \n",
    "        pass\n",
    "    \n",
    "    if bool(time_i_sci) == True: #if there are any points int he science i badn, plot them down\n",
    "#         plt.title('RA: '+ str(RA_sci.iloc[0]) + ' Dec: '+  str(Dec_sci.iloc[0]))\n",
    "        ax2.set_xlabel('Date')\n",
    "        ax2.set_ylabel('Magnitude in science image', color = 'black')\n",
    "        ax2.invert_yaxis()\n",
    "        try:\n",
    "            ax2.plot(time_i_sci, mag_i_sci, color = 'grey', marker = 'o', label = 'i')\n",
    "        except(ValueError):\n",
    "            pass\n",
    "        \n",
    "        plt.legend()\n",
    "        \n",
    "        ax3 = ax2.twinx()  # initiates a second axes that shares the same x-axis for the 'colour' plot \n",
    "        ax3.set_ylabel('g - i', color = 'r')  # we already handled the x-label with ax1\n",
    "        ax3.tick_params(axis='y', labelcolor = 'r')\n",
    "        ax3.invert_yaxis()\n",
    "        try: \n",
    "            ax3.plot(time_g_sci, mag_diff_sci, color = 'r', marker = 'x', label = 'g-i')\n",
    "        except(ValueError):\n",
    "            pass\n",
    "        \n",
    "    else:\n",
    "        plt.legend()\n",
    "        pass\n",
    "    \n",
    "#     plt.locator_params(axis = 'y', nbins = 10) #limiting the x-axis and y-axis\n",
    "#     plt.locator_params(axis='x', nbins=10)\n",
    "    \n",
    "    plt.savefig(results_dir + 'CAND_'+ str(i) + '_RA: '+ str(RA_sub.iloc[0]) + '_Dec: '+  str(Dec_sub.iloc[0]) + 'Lightcurve' + '.png', format = 'png') #saving the light curve as an image\n",
    "    # the results_dir tells python to save the file in that specific directory\n",
    "    \n",
    "    plt.close() #closing plots to save memory etc \n",
    "    \n",
    "    if i % 10 == 0: #printing progress every 10 iterations\n",
    "        print('i = {}'.format(i) + '/' + str(len(data1_123_matches)))\n",
    "        \n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "# Exporting the data onto a csv file \n",
    "        \n",
    "gsub1 = gsub1.reset_index()\n",
    "gsub2 = gsub2.reset_index()\n",
    "gsub3 = gsub3.reset_index()\n",
    "isub1 = isub1.reset_index()\n",
    "isub2 = isub2.reset_index()\n",
    "isub3 = isub3.reset_index()\n",
    "gsci1 = gsci1.reset_index()\n",
    "gsci2 = gsci2.reset_index()\n",
    "gsci3 = gsci3.reset_index()\n",
    "isci1 = isci1.reset_index()\n",
    "isci2 = isci2.reset_index()\n",
    "isci3 = isci3.reset_index()\n",
    "\n",
    "xgsub1 = xgsub1.reset_index()\n",
    "xgsub2 = xgsub2.reset_index()\n",
    "xgsub3 = xgsub3.reset_index()\n",
    "ygsub1 = ygsub1.reset_index()\n",
    "ygsub2 = ygsub2.reset_index()\n",
    "ygsub3 = ygsub3.reset_index()\n",
    "xgsci1 = xgsci1.reset_index()\n",
    "xgsci2 = xgsci2.reset_index()\n",
    "xgsci3 = xgsci3.reset_index()\n",
    "ygsci1 = ygsci1.reset_index()\n",
    "ygsci2 = ygsci2.reset_index()\n",
    "ygsci3 = ygsci3.reset_index()\n",
    "\n",
    "xisub1 = xisub1.reset_index()\n",
    "xisub2 = xisub2.reset_index()\n",
    "xisub3 = xisub3.reset_index()\n",
    "yisub1 = yisub1.reset_index()\n",
    "yisub2 = yisub2.reset_index()\n",
    "yisub3 = yisub3.reset_index()\n",
    "xisci1 = xisci1.reset_index()\n",
    "xisci2 = xisci2.reset_index()\n",
    "xisci3 = xisci3.reset_index()\n",
    "yisci1 = yisci1.reset_index()\n",
    "yisci2 = yisci2.reset_index()\n",
    "yisci3 = yisci3.reset_index()\n",
    "\n",
    "FWHMgsub1 = FWHMgsub1.reset_index()\n",
    "FWHMgsub2 = FWHMgsub2.reset_index()\n",
    "FWHMgsub3 = FWHMgsub3.reset_index()\n",
    "FWHMisub1 = FWHMisub1.reset_index()\n",
    "FWHMisub2 = FWHMisub2.reset_index()\n",
    "FWHMisub3 = FWHMisub3.reset_index()\n",
    "FWHMgsci1 = FWHMgsci1.reset_index()\n",
    "FWHMgsci2 = FWHMgsci2.reset_index()\n",
    "FWHMgsci3 = FWHMgsci3.reset_index()\n",
    "FWHMisci1 = FWHMisci1.reset_index()\n",
    "FWHMisci2 = FWHMisci2.reset_index()\n",
    "FWHMisci3 = FWHMisci3.reset_index()\n",
    "\n",
    "mag_csv = mag_csv.assign(gsub1 = gsub1['MAG_AUTO'] , gsub2 = gsub2['MAG_AUTO'], gsub3 = gsub3['MAG_AUTO'], \n",
    "                        isub1 = isub1['MAG_AUTO'], isub2 = isub2['MAG_AUTO'], isub3 = isub3['MAG_AUTO'],\n",
    "                        gsci1 = gsci1['MAG_AUTO'] , gsci2 = gsci2['MAG_AUTO'], gsci3 = gsci3['MAG_AUTO'],\n",
    "                        isci1 = isci1['MAG_AUTO'] , isci2 = isci2['MAG_AUTO'], isci3 = isci3['MAG_AUTO'],\n",
    "                         \n",
    "                        xgsub1 = xgsub1['X_WORLD'], xgsub2 = xgsub2['X_WORLD'], xgsub3 = xgsub3['X_WORLD'],\n",
    "                        ygsub1 = ygsub1['Y_WORLD'], ygsub2 = ygsub2['Y_WORLD'], ygsub3 = ygsub3['Y_WORLD'],\n",
    "                        xgsci1 = xgsci1['X_WORLD'], xgsci2 = xgsci2['X_WORLD'], xgsci3 = xgsci3['X_WORLD'],\n",
    "                        ygsci1 = ygsci1['Y_WORLD'], ygsci2 = ygsci2['Y_WORLD'], ygsci3 = ygsci3['Y_WORLD'],\n",
    "                         \n",
    "                        xisub1 = xisub1['X_WORLD'], xisub2 = xisub2['X_WORLD'], xisub3 = xisub3['X_WORLD'],\n",
    "                        yisub1 = yisub1['Y_WORLD'], yisub2 = yisub2['Y_WORLD'], yisub3 = yisub3['Y_WORLD'],\n",
    "                        xisci1 = xisci1['X_WORLD'], xisci2 = xisci2['X_WORLD'], xisci3 = xisci3['X_WORLD'],\n",
    "                        yisci1 = yisci1['Y_WORLD'], yisci2 = yisci2['Y_WORLD'], yisci3 = yisci3['Y_WORLD'],\n",
    "                         \n",
    "                        FWHMgsub1 = FWHMgsub1['FWHM_WORLD'], FWHMgsub2 = FWHMgsub2['FWHM_WORLD'], FWHMgsub3 = FWHMgsub3['FWHM_WORLD'],\n",
    "                        FWHMisub1 = FWHMisub1['FWHM_WORLD'], FWHMisub2 = FWHMisub2['FWHM_WORLD'], FWHMisub3 = FWHMisub3['FWHM_WORLD'],\n",
    "                        FWHMgsci1 = FWHMgsci1['FWHM_WORLD'], FWHMgsci2 = FWHMgsci2['FWHM_WORLD'], FWHMgsci3 = FWHMgsci3['FWHM_WORLD'],\n",
    "                        FWHMisci1 = FWHMisci1['FWHM_WORLD'], FWHMisci2 = FWHMisci2['FWHM_WORLD'], FWHMisci3 = FWHMisci3['FWHM_WORLD'])\n",
    "                        \n",
    "\n",
    "\n",
    "mag_csv.to_csv(results_dir + 'Sources.csv') #writing out all of the magnitudes into a csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
